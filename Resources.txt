{'Survey': [{'title': 'Reasoning with Language Model Prompting: A Survey.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.09597',
    '[code': 'https://github.com/zjunlp/Prompt4ReasoningPapers'}},
  {'title': 'Towards Reasoning in Large Language Models: A Survey.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.10403',
    '[code': 'https://github.com/jeffhj/LM-reasoning'}},
  {'title': 'Large Language Models for Mathematical Reasoning: Progresses and Challenges.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.00157'}},
  {'title': 'Puzzle Solving using Reasoning of Large Language Models: A Survey.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.11291',
    '[code': 'https://puzzlellms.github.io/'}}],
 'Analysis': [{'title': 'Can language models learn from explanations in context?',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2204.02329'}},
  {'title': 'Emergent Abilities of Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2206.07682',
    '[blog': 'https://ai.googleblog.com/2022/11/characterizing-emergent-phenomena-in.html'}},
  {'title': 'Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.09261',
    '[code': 'https://github.com/suzgunmirac/BIG-Bench-Hard'}},
  {'title': 'Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.10001',
    '[code': 'https://github.com/sunlab-osu/Understanding-CoT'}},
  {'title': "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning.",
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.08061'}},
  {'title': 'Dissociating language and thought in large language models: a cognitive perspective.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2301.06627'}},
  {'title': 'Large Language Models Can Be Easily Distracted by Irrelevant Context.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2302.00093'}},
  {'title': 'A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2302.04023'}},
  {'title': "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting.",
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.04388',
    '[code': 'https://github.com/milesaturpin/cot-unfaithfulness'}},
  {'title': 'Faith and Fate: Limits of Transformers on Compositionality.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.18654'}},
  {'title': 'Measuring Faithfulness in Chain-of-Thought Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2307.13702'}},
  {'title': 'Large Language Models Cannot Self-Correct Reasoning Yet.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2310.01798'}},
  {'title': 'The Impact of Reasoning Step Length on Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2401.04925'}},
  {'title': 'Premise Order Matters in Reasoning with Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.08939'}},
  {'title': 'Do Large Language Models Latently Perform Multi-Hop Reasoning?',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.16837'}},
  {'title': 'How Far Are We from Intelligent Visual Deductive Reasoning?',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2403.04732'}},
  {'title': 'Chain of Thought Prompting Elicits Reasoning in Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2201.11903',
    '[blog': 'https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html'}},
  {'title': 'Self-consistency improves chain of thought reasoning in language models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2203.11171'}},
  {'title': 'Iteratively Prompt Pre-trained Language Models for Chain of Thought.',
   'authors': '',
   'conference': '',
   'year': '2203',
   'links': {'[paper': 'https://arxiv.org/abs/2203.08383',
    '[code': 'https://github.com/sunlab-osu/iterprompt'}},
  {'title': 'Least-to-most prompting enables complex reasoning in large language models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2205.10625'}},
  {'title': 'Large Language Models are Zero-Shot Reasoners.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2205.11916'}},
  {'title': 'Making Large Language Models Better Reasoners with Step-Aware Verifier.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2206.02336'}},
  {'title': "Large Language Models Still Can't Plan.",
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2206.10498',
    '[code': 'https://github.com/karthikv792/gpt-plan-benchmark'}},
  {'title': 'Solving Quantitative Reasoning Problems with Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2206.14858',
    '[blog': 'https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html'}},
  {'title': 'Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[project': 'https://promptpg.github.io/',
    '[paper': 'https://arxiv.org/abs/2209.14610',
    '[code': 'https://github.com/lupantech/PromptPG'}},
  {'title': 'Ask Me Anything: A simple strategy for prompting language models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.02441',
    '[code': 'https://github.com/hazyresearch/ama_prompting'}},
  {'title': 'Language Models are Multilingual Chain-of-Thought Reasoners.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.03057'}},
  {'title': 'Automatic Chain of Thought Prompting in Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.03493',
    '[code': 'https://github.com/amazon-research/auto-cot'}},
  {'title': "Mind's Eye: Grounded language model reasoning through simulation.",
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.05359'}},
  {'title': 'Language Models of Code are Few-Shot Commonsense Learners.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.07128',
    '[code': 'https://github.com/madaan/cocogen'}},
  {'title': 'Large Language Models Can Self-Improve.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.11610'}},
  {'title': 'Retrieval Augmentation for Commonsense Reasoning: A Unified Approach.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.12887',
    '[code': 'https://github.com/wyu97/RACo'}},
  {'title': 'Solving Math Word Problems via Cooperative Reasoning induced Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.16257',
    '[code': 'https://github.com/TianHongZXY/CoRe'}},
  {'title': 'PAL: Program-aided Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[project': 'https://reasonwithpal.com/',
    '[paper': 'https://arxiv.org/abs/2211.10435',
    '[code': 'https://github.com/reasoning-machines/pal'}},
  {'title': 'Unsupervised Explanation Generation via Correct Instantiations.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2211.11160'}},
  {'title': 'Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2211.12588',
    '[code': 'https://github.com/wenhuchen/program-of-thoughts'}},
  {'title': 'Complementary Explanations for Effective In-Context Learning.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2211.13892'}},
  {'title': 'Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.09146',
    '[code': 'https://github.com/McGill-NLP/retriever-lm-reasoning'}},
  {'title': 'Large Language Models are reasoners with Self-Verification.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.09561',
    '[code': 'https://github.com/WENGSYX/Self-Verification'}},
  {'title': 'Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.10509',
    '[code': 'https://github.com/StonyBrookNLP/ircot'}},
  {'title': 'Language Models as Inductive Reasoners.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.10923'}},
  {'title': 'LAMBADA: Backward Chaining for Automated Reasoning in Natural Language.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.13894'}},
  {'title': 'Rethinking with Retrieval: Faithful Large Language Model Inference.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2301.00303'}},
  {'title': 'Faithful Chain-of-Thought Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2301.13379'}},
  {'title': 'Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2302.00618'}},
  {'title': 'Active Prompting with Chain-of-Thought for Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2302.12246',
    '[code': 'https://github.com/shizhediao/active-cot'}},
  {'title': 'Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2302.12822',
    '[code': 'https://github.com/shizhediao/automate-cot'}},
  {'title': 'ART: Automatic multi-step reasoning and tool-use for large language models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2303.09014'}},
  {'title': 'REFINER: Reasoning Feedback on Intermediate Representations.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[project': 'https://debjitpaul.github.io/refiner/',
    '[paper': 'https://arxiv.org/abs/2304.01904',
    '[code': 'https://github.com/debjitpaul/refiner'}},
  {'title': 'SatLM: Satisfiability-Aided Language Models Using Declarative Prompting',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.09656',
    '[code': 'https://github.com/xiye17/sat-lm'}},
  {'title': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.10601',
    '[code': 'https://github.com/ysymyth/tree-of-thought-llm'}},
  {'title': 'Reasoning Implicit Sentiment with Chain-of-Thought Prompting',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.11255',
    '[code': 'https://github.com/scofield7419/THOR-ISA'}},
  {'title': 'Reasoning with Language Model is Planning with World Model.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.14992'}},
  {'title': 'Recursion of Thought: A Divide and Conquer Approach to Multi-Context Reasoning with Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2306.06891',
    '[code': 'https://github.com/soochan-lee/RoT',
    '[poster': 'https://soochanlee.com/img/rot/rot_poster.pdf'}},
  {'title': 'Question Decomposition Improves the Faithfulness of Model-Generated Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2307.11768',
    '[code': 'https://github.com/anthropics/DecompositionFaithfulnessPaper'}},
  {'title': 'Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2307.15337'}},
  {'title': 'Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2308.00304'}},
  {'title': 'Chain-of-Verification Reduces Hallucination in Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2309.11495'}},
  {'title': 'Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2309.13339',
    '[code': 'https://github.com/xf-zhao/LoT'}},
  {'title': 'Enable Language Models to Implicitly Learn Self-Improvement From Data.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2310.00898'}},
  {'title': 'Improving Large Language Model Fine-tuning for Solving Math Problems.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2310.10047'}},
  {'title': 'Teaching Language Models to Self-Improve through Interactive Demonstrations.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2310.13522'}},
  {'title': 'Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.12295',
    '[code': 'https://github.com/teacherpeterpan/Logic-LLM'}},
  {'title': 'Boosting LLM Reasoning: Push the Limits of Few-shot Learning with Reinforced In-Context Pruning',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2312.08901'}},
  {'title': 'Efficient Tool Use with Chain-of-Abstraction Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2401.17464'}},
  {'title': 'K-Level Reasoning with Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.01521'}},
  {'title': 'DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.03300'}},
  {'title': 'Self-Discover: Large Language Models Self-Compose Reasoning Structures.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.03620'}},
  {'title': 'InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.06332'}},
  {'title': 'Chain-of-Thought Reasoning Without Prompting.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.10200'}},
  {'title': 'GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.10963'}},
  {'title': 'LLM3:Large Language Model-based Task and Motion Planning with Motion Failure Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2403.11552',
    '[code': 'https://github.com/AssassinWS/LLM-TAMP'}},
  {'title': 'Teaching Large Language Models to Reason with Reinforcement Learning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2403.04642'}},
  {'title': 'Advancing LLM Reasoning Generalists with Preference Trees.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2404.02078'}},
  {'title': 'Evaluating Mathematical Reasoning Beyond Accuracy.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2404.05692'}},
  {'title': 'Self-playing Adversarial Language Game Enhances LLM Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2404.10642'}},
  {'title': 'Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2404.12253'}},
  {'title': '',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2406.14283'}},
  {'title': 'LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2406.17663'}},
  {'title': 'Scaling Instruction-Finetuned Language Models.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2210.11416'}},
  {'title': 'Distilling Multi-Step Reasoning Capabilities of Large Language Models into Smaller Models via Semantic Decompositions.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.00193'}},
  {'title': 'Teaching Small Language Models to Reason.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.08410'}},
  {'title': 'Large Language Models Are Reasoning Teachers.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[paper': 'https://arxiv.org/abs/2212.10071',
    '[code': 'https://github.com/itsnamgyu/reasoning-teacher'}},
  {'title': 'Specializing Smaller Language Models towards Multi-Step Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2301.12726'}},
  {'title': 'Symbolic Chain-of-Thought Distillation: Small Models Can Also "Think" Step-by-Step.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2306.14050',
    '[code': 'https://github.com/allenai/cot_distillation'}},
  {'title': 'Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2308.07336',
    '[code': 'https://github.com/hitachi-nlp/FLD'}},
  {'title': 'Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2402.13950',
    '[code': 'https://github.com/debjitpaul/causal_CoT'}},
  {'title': 'MathScale: Scaling Instruction Tuning for Mathematical Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2403.02884'}},
  {'title': 'Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[project': 'https://socraticmodels.github.io/',
    '[paper': 'https://arxiv.org/abs/2204.00598',
    '[code': 'https://github.com/google-research/google-research/tree/master/socraticmodels'}},
  {'title': 'Visual Programming: Compositional visual reasoning without training.',
   'authors': '',
   'conference': '',
   'year': '2022',
   'links': {'[project': 'https://prior.allenai.org/projects/visprog',
    '[paper': 'https://arxiv.org/abs/2211.11559',
    '[code': 'https://github.com/allenai/visprog'}},
  {'title': 'Multimodal Chain-of-Thought Reasoning in Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2302.00923',
    '[code': 'https://github.com/amazon-science/mm-cot'}},
  {'title': 'Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2303.04671',
    '[code': 'https://github.com/microsoft/visual-chatgpt'}},
  {'title': 'ViperGPT: Visual Inference via Python Execution for Reasoning.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[project': 'https://viper.cs.columbia.edu/',
    '[paper': 'https://arxiv.org/abs/2303.08128',
    '[code': 'https://github.com/cvlab-columbia/viper'}},
  {'title': 'MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[project': 'https://multimodal-react.github.io/',
    '[paper': 'https://arxiv.org/abs/2303.11381',
    '[code': 'https://github.com/microsoft/MM-REACT',
    '[demo': 'https://huggingface.co/spaces/microsoft-cognitive-service/mm-react'}},
  {'title': 'Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[project': 'https://chameleon-llm.github.io/',
    '[paper': 'https://arxiv.org/abs/2304.09842',
    '[code': 'https://github.com/lupantech/chameleon-llm'}},
  {'title': 'Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2305.02317',
    '[code': 'https://github.com/dannyrose30/VCOT'}},
  {'title': 'Link-Context Learning for Multimodal LLMs.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2308.07891',
    '[code': 'https://github.com/isekai-portal/Link-Context-Learning'}},
  {'title': 'G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2312.11370'}},
  {'title': 'Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models.',
   'authors': '',
   'conference': '',
   'year': '2023',
   'links': {'[paper': 'https://arxiv.org/abs/2312.17661'}},
  {'title': 'Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[paper': 'https://arxiv.org/abs/2401.04398'}},
  {'title': 'SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities.',
   'authors': '',
   'conference': '',
   'year': '2024',
   'links': {'[project': 'https://spatial-vlm.github.io/',
    '[paper': 'https://arxiv.org/abs/2401.12168'}},
  {'title': 'Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs.',
   'authors': '',
   'conference': '',
   'year': '2307',
   'links': {'[paper': 'https://arxiv.org/abs/2403.12596',
    'gsm8k': 'https://arxiv.org/abs/2110.14168',
    'svamp': 'https://aclanthology.org/2021.naacl-main.168',
    'asdiv': 'https://aclanthology.org/2020.acl-main.92/',
    'aqua': 'https://aclanthology.org/P17-1015/',
    'mawps': 'https://aclanthology.org/N16-1136/',
    'addsub': 'https://aclanthology.org/D14-1058/',
    'multiarith': 'https://aclanthology.org/D15-1202/',
    'singleeq': 'https://aclanthology.org/Q15-1042/',
    'singleop': ' https://doi.org/10.1162/tacl_a_00118',
    'lila': 'https://arxiv.org/abs/2210.17517',
    'commonsenseqa': 'https://arxiv.org/abs/1811.00937',
    'strategyqa': 'https://arxiv.org/abs/2101.02235',
    'arc': 'https://arxiv.org/abs/1911.01547',
    'boolq': 'https://arxiv.org/abs/1905.10044',
    'hotpotqa': 'https://arxiv.org/abs/1809.09600',
    'openbookqa': 'https://arxiv.org/abs/1809.02789',
    'piqa': 'https://arxiv.org/abs/1911.11641',
    'coinflip': 'https://arxiv.org/abs/2201.11903',
    'lastletterconcatenation': 'https://arxiv.org/abs/2201.11903',
    'reverselist': 'https://arxiv.org/abs/2201.11903v1',
    'reclor': 'https://arxiv.org/abs/2002.04326',
    'logiqa': 'https://arxiv.org/abs/2007.08124',
    'proofwriter': 'https://arxiv.org/abs/2012.13048',
    'fld': 'https://arxiv.org/abs/2308.07336',
    'folio': 'https://arxiv.org/abs/2209.00840',
    'scienceqa': 'https://arxiv.org/abs/2209.09513',
    'aro': 'https://arxiv.org/abs/2210.01936',
    'ok-vqa': 'https://arxiv.org/abs/1906.00067',
    'a-okvqa': 'https://arxiv.org/abs/2206.01718',
    'next-qa': 'https://arxiv.org/abs/2105.08276',
    'gqa': 'https://arxiv.org/abs/1902.09506',
    'vqa': 'https://arxiv.org/abs/1505.00468',
    'vqav2': 'https://arxiv.org/abs/1612.00837',
    'tag': 'https://arxiv.org/abs/2208.01813',
    'bongard-hoi': 'https://arxiv.org/abs/2205.13803',
    'arb': 'https://arxiv.org/abs/2307.13692',
    'big-bench': 'https://doi.org/10.48550/arXiv.2206.04615',
    'agieval': 'https://arxiv.org/abs/2304.06364',
    'alert': 'https://arxiv.org/abs/2212.08286',
    'condaqa': 'https://arxiv.org/abs/2211.00295',
    'scan': 'https://arxiv.org/abs/1711.00350',
    'wikiwhy': 'https://arxiv.org/abs/2210.12152',
    'here': 'https://github.com/atfortes/DataGenLM'}}],
 'Other Useful Resources': [],
 'Other Awesome Lists': [],
 'Contributing': []}
